{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7951820,"sourceType":"datasetVersion","datasetId":4676431}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets bitsandbytes accelerate peft","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-28T01:21:46.822576Z","iopub.execute_input":"2024-03-28T01:21:46.822909Z","iopub.status.idle":"2024-03-28T01:22:06.407787Z","shell.execute_reply.started":"2024-03-28T01:21:46.822877Z","shell.execute_reply":"2024-03-28T01:22:06.406895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade accelerate\n!pip install bitsandbytes transformers_stream_generator","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-03-28T01:22:06.410284Z","iopub.execute_input":"2024-03-28T01:22:06.411054Z","iopub.status.idle":"2024-03-28T01:22:34.244520Z","shell.execute_reply.started":"2024-03-28T01:22:06.411011Z","shell.execute_reply":"2024-03-28T01:22:34.243604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n!pip install -q datasets","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:22:34.246110Z","iopub.execute_input":"2024-03-28T01:22:34.246480Z","iopub.status.idle":"2024-03-28T01:24:46.205709Z","shell.execute_reply.started":"2024-03-28T01:22:34.246444Z","shell.execute_reply":"2024-03-28T01:24:46.204351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom datasets import Dataset, load_dataset\nfrom peft import  LoraConfig, get_peft_model\nfrom peft import prepare_model_for_kbit_training\nimport bitsandbytes as bnb\nfrom transformers import GPT2LMHeadModel, BitsAndBytesConfig\nfrom transformers import GPT2Tokenizer, AutoModelForCausalLM\nimport transformers","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:24:46.208589Z","iopub.execute_input":"2024-03-28T01:24:46.208918Z","iopub.status.idle":"2024-03-28T01:25:00.249793Z","shell.execute_reply.started":"2024-03-28T01:24:46.208887Z","shell.execute_reply":"2024-03-28T01:25:00.248963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries_path = '/kaggle/input/list-of-arabic-instruction-query/list_of_queries.json'\nqueries_data = pd.read_json(queries_path)\nold_column_name = queries_data.columns[0] \nnew_column_name = 'queries'\nqueries_data = queries_data.rename(columns={old_column_name: new_column_name})","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:25:00.250879Z","iopub.execute_input":"2024-03-28T01:25:00.251312Z","iopub.status.idle":"2024-03-28T01:25:15.851445Z","shell.execute_reply.started":"2024-03-28T01:25:00.251286Z","shell.execute_reply":"2024-03-28T01:25:15.850659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries_data.columns[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:25:15.852788Z","iopub.execute_input":"2024-03-28T01:25:15.853604Z","iopub.status.idle":"2024-03-28T01:25:15.860578Z","shell.execute_reply.started":"2024-03-28T01:25:15.853568Z","shell.execute_reply":"2024-03-28T01:25:15.859611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef max_len(text):\n    pattern = r'[\\s\\n،؛؟\\.،:؛!\"\\'()&*+,،\\-./:;<=>؟]'\n\n    # Split the text using the regular expression pattern\n    tokens = re.split(pattern, text)\n    \n    # [token.strip() for token in tokens if token.strip()]\n    \n    return max(len(token.strip()) for token in tokens if token.strip())\n\n\ndef count_words(text):\n    pattern = r'[\\s\\n،؛؟\\.،:؛!\"\\'()&*+,،\\-./:;<=>؟]'\n\n    # Split the text using the regular expression pattern\n    tokens = re.split(pattern, text)\n    \n    return len([token.strip() for token in tokens if token.strip()])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:25:15.861821Z","iopub.execute_input":"2024-03-28T01:25:15.862186Z","iopub.status.idle":"2024-03-28T01:25:15.871886Z","shell.execute_reply.started":"2024-03-28T01:25:15.862158Z","shell.execute_reply":"2024-03-28T01:25:15.871179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries_data['max length of words'] = queries_data['queries'].map(max_len)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:25:15.872900Z","iopub.execute_input":"2024-03-28T01:25:15.873147Z","iopub.status.idle":"2024-03-28T01:25:57.573447Z","shell.execute_reply.started":"2024-03-28T01:25:15.873125Z","shell.execute_reply":"2024-03-28T01:25:57.572659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries_data['count of words'] = queries_data['queries'].map(count_words)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:25:57.574567Z","iopub.execute_input":"2024-03-28T01:25:57.574889Z","iopub.status.idle":"2024-03-28T01:26:36.103136Z","shell.execute_reply.started":"2024-03-28T01:25:57.574862Z","shell.execute_reply":"2024-03-28T01:26:36.102364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length_counts = queries_data['max length of words'].value_counts()\nlength_counts_df = pd.DataFrame({'length': length_counts.index, 'count': length_counts.values})\nlength_counts_df = length_counts_df.sort_values(by='length', ascending=True)\nlength_counts_df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:30:32.099977Z","iopub.execute_input":"2024-03-28T01:30:32.100343Z","iopub.status.idle":"2024-03-28T01:30:32.139402Z","shell.execute_reply.started":"2024-03-28T01:30:32.100314Z","shell.execute_reply":"2024-03-28T01:30:32.138569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nlength_counts_df = length_counts_df[length_counts_df['length']<150]\nplt.figure(figsize=(10, 6))\n\n# Plot the number of words against their counts\nplt.bar(length_counts_df['length'], length_counts_df['count'], color='skyblue')\n\n# Set labels and title\nplt.xlabel('length of Words')\nplt.ylabel('Count')\nplt.title('Frequency of length of Words')\n\n# Rotate x-axis labels for better readability if necessary\nplt.xticks(rotation=45)\n\n# Show plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:30:35.165004Z","iopub.execute_input":"2024-03-28T01:30:35.165370Z","iopub.status.idle":"2024-03-28T01:30:35.741409Z","shell.execute_reply.started":"2024-03-28T01:30:35.165340Z","shell.execute_reply":"2024-03-28T01:30:35.740407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length_counts_df","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:30:35.743320Z","iopub.execute_input":"2024-03-28T01:30:35.743792Z","iopub.status.idle":"2024-03-28T01:30:35.754532Z","shell.execute_reply.started":"2024-03-28T01:30:35.743755Z","shell.execute_reply":"2024-03-28T01:30:35.753553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_counts = queries_data['count of words'].value_counts()\nword_counts_df = pd.DataFrame({'number of words': word_counts.index, 'count': word_counts.values})\nword_counts_df = word_counts_df.sort_values(by='number of words', ascending=True)\nword_counts_df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:30:35.879412Z","iopub.execute_input":"2024-03-28T01:30:35.880109Z","iopub.status.idle":"2024-03-28T01:30:35.900516Z","shell.execute_reply.started":"2024-03-28T01:30:35.880083Z","shell.execute_reply":"2024-03-28T01:30:35.899700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nword_counts_df = word_counts_df[word_counts_df['number of words']<2000]\n\n# Set figure size\nplt.figure(figsize=(10, 6))\n\n# Plot the number of words against their counts\nplt.bar(word_counts_df['number of words'], word_counts_df['count'], color='skyblue')\n\n# Set labels and title\nplt.xlabel('Number of Words')\nplt.ylabel('Count')\nplt.title('Frequency of Number of Words')\n\n# Rotate x-axis labels for better readability if necessary\nplt.xticks(rotation=45)\n\n# Show plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:30:36.131919Z","iopub.execute_input":"2024-03-28T01:30:36.132204Z","iopub.status.idle":"2024-03-28T01:30:38.752227Z","shell.execute_reply.started":"2024-03-28T01:30:36.132181Z","shell.execute_reply":"2024-03-28T01:30:38.751290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_counts_df","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:30:38.754018Z","iopub.execute_input":"2024-03-28T01:30:38.754303Z","iopub.status.idle":"2024-03-28T01:30:38.765075Z","shell.execute_reply.started":"2024-03-28T01:30:38.754276Z","shell.execute_reply":"2024-03-28T01:30:38.764018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries_data.describe()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:30:38.766350Z","iopub.execute_input":"2024-03-28T01:30:38.766901Z","iopub.status.idle":"2024-03-28T01:30:38.807469Z","shell.execute_reply.started":"2024-03-28T01:30:38.766870Z","shell.execute_reply":"2024-03-28T01:30:38.806527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(queries_data[(queries_data['count of words'] < 300) & (queries_data['max length of words'] < 14)])/len(queries_data)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:30:38.809509Z","iopub.execute_input":"2024-03-28T01:30:38.809815Z","iopub.status.idle":"2024-03-28T01:30:38.844414Z","shell.execute_reply.started":"2024-03-28T01:30:38.809789Z","shell.execute_reply":"2024-03-28T01:30:38.843605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_queries_data = queries_data[(queries_data['count of words'] < 300) & (queries_data['max length of words'] < 14)]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:30:38.845409Z","iopub.execute_input":"2024-03-28T01:30:38.845673Z","iopub.status.idle":"2024-03-28T01:30:38.862635Z","shell.execute_reply.started":"2024-03-28T01:30:38.845651Z","shell.execute_reply":"2024-03-28T01:30:38.861970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries_dataset = Dataset.from_dict({'queries': clean_queries_data['queries'].tolist()})\nqueries_dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:33:04.209110Z","iopub.execute_input":"2024-03-28T01:33:04.209467Z","iopub.status.idle":"2024-03-28T01:33:05.175878Z","shell.execute_reply.started":"2024-03-28T01:33:04.209439Z","shell.execute_reply":"2024-03-28T01:33:05.174903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(queries_dataset['queries'][0])","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:33:10.095055Z","iopub.execute_input":"2024-03-28T01:33:10.095417Z","iopub.status.idle":"2024-03-28T01:33:11.068450Z","shell.execute_reply.started":"2024-03-28T01:33:10.095389Z","shell.execute_reply":"2024-03-28T01:33:11.067432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import random_split\nseed = 420\ngenerator = torch.Generator().manual_seed(seed)\n\n\nlength = len(queries_dataset)\nnum_sample = 4\nsize_sample = length//num_sample\npart4_length = length - 3*size_sample\n\npart1, part2, part3, part4 = random_split(queries_dataset, [size_sample, size_sample, size_sample, part4_length], generator=generator)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:33:14.831496Z","iopub.execute_input":"2024-03-28T01:33:14.832277Z","iopub.status.idle":"2024-03-28T01:33:14.876286Z","shell.execute_reply.started":"2024-03-28T01:33:14.832243Z","shell.execute_reply":"2024-03-28T01:33:14.875511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def subset_to_dataset(subset):\n    data = {}\n    for key in subset.dataset[0].keys():\n        data[key] = []\n\n    for idx in subset.indices:\n        for key, value in subset.dataset[idx].items():\n            data[key].append(value)\n\n    return Dataset.from_dict(data)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:35:23.080473Z","iopub.execute_input":"2024-03-28T01:35:23.081136Z","iopub.status.idle":"2024-03-28T01:35:23.086910Z","shell.execute_reply.started":"2024-03-28T01:35:23.081106Z","shell.execute_reply":"2024-03-28T01:35:23.086041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"part1_of_dataset = subset_to_dataset(part1)\npart2_of_dataset = subset_to_dataset(part2)\npart3_of_dataset = subset_to_dataset(part3)\npart4_of_dataset = subset_to_dataset(part4)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:36:12.996056Z","iopub.execute_input":"2024-03-28T01:36:12.996832Z","iopub.status.idle":"2024-03-28T01:36:21.766961Z","shell.execute_reply.started":"2024-03-28T01:36:12.996801Z","shell.execute_reply":"2024-03-28T01:36:21.765958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"part1_of_dataset,part1_of_dataset, part1_of_dataset,part1_of_dataset , part1_of_dataset['queries'][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:37:17.786140Z","iopub.execute_input":"2024-03-28T01:37:17.786955Z","iopub.status.idle":"2024-03-28T01:37:18.004243Z","shell.execute_reply.started":"2024-03-28T01:37:17.786924Z","shell.execute_reply":"2024-03-28T01:37:18.003302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bnb_config = transformers.BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n) # setup bits and bytes config\n\nmodel_checkpoint = 'aubmindlab/aragpt2-medium'\nmodel = transformers.GPT2LMHeadModel.from_pretrained(model_checkpoint, quantization_config=bnb_config, device_map='balanced')\nmodel.config.pretraining_tp = 1\nmodel.config.use_cache = False\n#model = GPT2LMHeadModel.from_pretrained(model_checkpoint, quantization_config=bnb_config, device_map=\"auto\",)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:58:30.642308Z","iopub.execute_input":"2024-03-28T01:58:30.642955Z","iopub.status.idle":"2024-03-28T01:58:33.236538Z","shell.execute_reply.started":"2024-03-28T01:58:30.642921Z","shell.execute_reply":"2024-03-28T01:58:33.235710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:38:47.266556Z","iopub.execute_input":"2024-03-28T01:38:47.267426Z","iopub.status.idle":"2024-03-28T01:38:47.275547Z","shell.execute_reply.started":"2024-03-28T01:38:47.267394Z","shell.execute_reply":"2024-03-28T01:38:47.274537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################################################################\n# QLoRA parameters\n###########################################################################\n# LoRA config based on QLoRA paper\nconfig = LoraConfig(\n    r=8 ,\n    lora_alpha=16,\n    target_modules=['c_attn'],  #['c_attn', 'c_proj', 'c_fc', 'lm_head']\n    lora_dropout=0.06,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n# tokenizer.pad_token_id = 0\n# model.gradient_checkpointing_enable()\n\n# prepare model for training\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, config)\n\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:58:37.012050Z","iopub.execute_input":"2024-03-28T01:58:37.012432Z","iopub.status.idle":"2024-03-28T01:58:37.069555Z","shell.execute_reply.started":"2024-03-28T01:58:37.012402Z","shell.execute_reply":"2024-03-28T01:58:37.068618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint, add_prefix_space=True, add_eos_token=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:40:46.508383Z","iopub.execute_input":"2024-03-28T01:40:46.509159Z","iopub.status.idle":"2024-03-28T01:40:48.288644Z","shell.execute_reply.started":"2024-03-28T01:40:46.509124Z","shell.execute_reply":"2024-03-28T01:40:48.287723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(examples):\n    # extract text\n    text = examples['queries']\n\n    tokenized_inputs = tokenizer(\n        text, \n        truncation=True,\n        return_tensors='pt',\n        max_length=400,\n        padding=\"max_length\",\n    )\n\n    return tokenized_inputs\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:47:00.095072Z","iopub.execute_input":"2024-03-28T01:47:00.095927Z","iopub.status.idle":"2024-03-28T01:47:00.100937Z","shell.execute_reply.started":"2024-03-28T01:47:00.095893Z","shell.execute_reply":"2024-03-28T01:47:00.099778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenize_dataset1 = part1_of_dataset.shuffle(seed = 42).map(tokenize_function) #, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:51:04.638689Z","iopub.execute_input":"2024-03-28T01:51:04.639466Z","iopub.status.idle":"2024-03-28T01:52:51.112747Z","shell.execute_reply.started":"2024-03-28T01:51:04.639431Z","shell.execute_reply":"2024-03-28T01:52:51.112010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenize_dataset1","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:52:57.008212Z","iopub.execute_input":"2024-03-28T01:52:57.008832Z","iopub.status.idle":"2024-03-28T01:52:57.014907Z","shell.execute_reply.started":"2024-03-28T01:52:57.008799Z","shell.execute_reply":"2024-03-28T01:52:57.013975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = tokenize_dataset1.remove_columns(['queries'])\n\nsplit_index = int(len(d) * 0.75)  # 75% for training, 25% for testing\n\n# Split the dataset into training and testing subsets\ntrain_dataset1 = Dataset.from_dict(d[:split_index])\ntest_dataset1 = Dataset.from_dict(d[split_index:])","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:54:10.543744Z","iopub.execute_input":"2024-03-28T01:54:10.544124Z","iopub.status.idle":"2024-03-28T01:54:38.637139Z","shell.execute_reply.started":"2024-03-28T01:54:10.544095Z","shell.execute_reply":"2024-03-28T01:54:38.636314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset1, test_dataset1","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:54:49.633964Z","iopub.execute_input":"2024-03-28T01:54:49.634323Z","iopub.status.idle":"2024-03-28T01:54:49.641065Z","shell.execute_reply.started":"2024-03-28T01:54:49.634298Z","shell.execute_reply":"2024-03-28T01:54:49.640020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = transformers.TrainingArguments(\n    output_dir= './outputOfTrain/',                                 # output directory\n    evaluation_strategy=\"steps\",                                   # evaluate each epoch\n    per_device_train_batch_size=16 ,                          # batch size for training\n    per_device_eval_batch_size=4,                                  # batch size for evaluation\n    num_train_epochs=0.2,                           # number of training epochs\n    gradient_checkpointing=True,\n    optim=\"paged_adamw_32bit\",\n    #logging_dir='./logs',                         # directory for storing logs\n    save_steps=50,                               # save checkpoint every n steps\n    logging_steps=10,                            # log training metrics every n steps\n    learning_rate=1e-3,                           # initial learning rate\n    weight_decay=0.01,                            # weight decay\n    warmup_steps=50,                             # number of warmup steps for learning rate scheduler\n    disable_tqdm=True,                           # enable tqdm progress bars\n    #report_to=[\"tensorboard\"],                    # report training results to TensorBoard\n    fp16=True,\n    max_grad_norm=0.3,\n    warmup_ratio=0.03,\n    overwrite_output_dir=True,\n    gradient_accumulation_steps=2,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T11:01:55.396595Z","iopub.execute_input":"2024-03-28T11:01:55.396987Z","iopub.status.idle":"2024-03-28T11:01:55.753540Z","shell.execute_reply.started":"2024-03-28T11:01:55.396955Z","shell.execute_reply":"2024-03-28T11:01:55.752190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''if torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    model = torch.nn.DataParallel(model)\ntorch.cuda.device_count()'''","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:57:35.655236Z","iopub.execute_input":"2024-03-28T01:57:35.655729Z","iopub.status.idle":"2024-03-28T01:57:35.665476Z","shell.execute_reply.started":"2024-03-28T01:57:35.655686Z","shell.execute_reply":"2024-03-28T01:57:35.664431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = transformers.Trainer(\n    model=model,\n    train_dataset = train_dataset1,\n    eval_dataset = test_dataset1,\n    args= training_args,\n    data_collator=transformers.DataCollatorForLanguageModeling(\n        tokenizer=tokenizer, mlm=False,\n    ),\n)\n# model.config.use_cache = False","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:58:48.303543Z","iopub.execute_input":"2024-03-28T01:58:48.304559Z","iopub.status.idle":"2024-03-28T01:58:48.316574Z","shell.execute_reply.started":"2024-03-28T01:58:48.304522Z","shell.execute_reply":"2024-03-28T01:58:48.315424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Training = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T01:58:50.840680Z","iopub.execute_input":"2024-03-28T01:58:50.841413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model('train/arabic-gpt2-m')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model_checkpoint, target_module, dataset):\n    bnb_config = transformers.BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.bfloat16\n    ) \n    model = transformers.GPT2LMHeadModel.from_pretrained(model_checkpoint, quantization_config=bnb_config, device_map='balanced')\n    model.config.pretraining_tp = 1\n    model.config.use_cache = False\n    \n    tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint, add_prefix_space=True, add_eos_token=True)\n    tokenizer.pad_token = tokenizer.eos_token\n    tokenizer.padding_side = \"right\"\n    \n    config = LoraConfig(\n        r=8 ,\n        lora_alpha=16,\n        target_modules=[target_module],  #['c_attn', 'c_proj', 'c_fc', 'lm_head']\n        lora_dropout=0.06,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\",\n    )\n    model = prepare_model_for_kbit_training(model)\n    model = get_peft_model(model, config)\n\n    print('print_trainable_parameters : ',model.print_trainable_parameters())\n\n    tokenize_dataset = dataset.shuffle(seed = 42).map(tokenize_function) #, batched=True)\n    \n    d = tokenize_dataset.remove_columns(['queries'])\n\n    split_index = int(len(d) * 0.75)  # 75% for training, 25% for testing\n\n    # Split the dataset into training and testing subsets\n    train_dataset = Dataset.from_dict(d[:split_index])\n    test_dataset = Dataset.from_dict(d[split_index:])\n    \n    training_args = transformers.TrainingArguments(\n                        output_dir= './outputOfTrain/',                                 # output directory\n                        evaluation_strategy=\"steps\",                                   # evaluate each epoch\n                        per_device_train_batch_size=16 ,                          # batch size for training\n                        per_device_eval_batch_size=4,                                  # batch size for evaluation\n                        num_train_epochs=1,                           # number of training epochs\n                        gradient_checkpointing=True,\n                        optim=\"paged_adamw_32bit\",\n                        #logging_dir='./logs',                         # directory for storing logs\n                        save_steps=50,                               # save checkpoint every n steps\n                        logging_steps=10,                            # log training metrics every n steps\n                        learning_rate=1e-3,                           # initial learning rate\n                        weight_decay=0.01,                            # weight decay\n                        warmup_steps=50,                             # number of warmup steps for learning rate scheduler\n                        disable_tqdm=True,                           # enable tqdm progress bars\n                        #report_to=[\"tensorboard\"],                    # report training results to TensorBoard\n                        fp16=True,\n                        max_grad_norm=0.3,\n                        warmup_ratio=0.03,\n                        overwrite_output_dir=True,\n                        gradient_accumulation_steps=2,\n                    )\n    \n    trainer = transformers.Trainer(\n                    model=model,\n                    train_dataset = train_dataset1,\n                    eval_dataset = test_dataset1,\n                    args= training_args,\n                    data_collator=transformers.DataCollatorForLanguageModeling(\n                        tokenizer=tokenizer, mlm=False,\n                    ),\n                )\n    \n    Training = trainer.train()\n    \n    trainer.save_model('train/arabic-gpt2-m')\n    \n    return model, Training","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}